{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 2.0.10 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below. Now we download required files and create an environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  8026  100  8026    0     0  49530      0 --:--:-- --:--:-- --:--:-- 54598\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2974  100  2974    0     0  22560      0 --:--:-- --:--:-- --:--:-- 22876\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1549  100  1549    0     0  11865      0 --:--:-- --:--:-- --:--:-- 12101\n"
     ]
    }
   ],
   "source": [
    "!rm ddpg_agent.py model.py\n",
    "!curl https://raw.githubusercontent.com/VVKot/deep-reinforcement-learning/master/p3_collab-compet/ddpg_agent.py --output ddpg_agent.py\n",
    "!curl https://raw.githubusercontent.com/VVKot/deep-reinforcement-learning/master/p3_collab-compet/model.py --output model.py\n",
    "!curl https://raw.githubusercontent.com/VVKot/deep-reinforcement-learning/master/p2_continuous-control/workspace_utils.py --output workspace_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from collections import deque\n",
    "from ddpg_agent import Agent\n",
    "from unityagents import UnityEnvironment\n",
    "from workspace_utils import active_session\n",
    "\n",
    "env = UnityEnvironment(file_name=\"/data/Tennis_Linux_NoVis/Tennis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TennisBrain\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "print(brain_name)\n",
    "print(brain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -6.65278625 -1.5        -0.          0.\n",
      "  6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):                                         # play game for 5 episodes\n",
    "#     env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "#     states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "#     scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "#     while True:\n",
    "#         actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "#         actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "#         env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "#         next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "#         rewards = env_info.rewards                         # get reward (for each agent)\n",
    "#         dones = env_info.local_done                        # see if episode finished\n",
    "#         scores += env_info.rewards                         # update the score (for each agent)\n",
    "#         states = next_states                               # roll over states to next time step\n",
    "#         if np.any(dones):                                  # exit loop if episode finished\n",
    "#             break\n",
    "#     print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can instantiate two agents to play tennis. We make the code more general since potentially the same approach might be applied for the environment with more than two agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "def create_agent(states, actions):\n",
    "    return Agent(states, actions, 0)\n",
    "\n",
    "agents = [create_agent(state_size, action_size) for _ in range(num_agents)] # create two agents to play tennis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A separate agent is created for both players.\n",
    "\n",
    "The agent is represented by two neural networks - Actor and Critic. Both of them are of equal size, with 512 neurons in each layer, and 4 layers. Network with 3 layers in my experience wasn't sufficient to achieve the task. Inner layers of both networks have leaky RELU activation function - in my experiments, it helped to converge faster compared to RELU/ELU. Since Actor has to produce values for actions, and we operate in continuos space where each action has to be a value from -1 to 1, is has a tanh activation function at the last layer. On the other hand, Critic produces Q values, that's why it does not have an activation function for the last layer at all. Both networks are trained using Adam optimizer. The choice of action is not greedy. Since we cannot use epsilon-greedy policy in continuous space, every action is changed slightly using Ornstein-Uhlenbeck noise.\n",
    "\n",
    "Learning is stabilized by using fixed Q-targets and soft updates.\n",
    "\n",
    "When evaluating the default model and agent from DDPG lesson versus the model and agent that I've used to solve P2, I found my implementation is more robust and is able to learn faster. I think the primary reason for that is the increased size of the network, using which agent can quickly learn more complex interaction - e.g. moving AND jumping. The parameter that had the most influence on the speed of the learning and convergence was the learning rate. After several unsuccessful options(from 10^-5 to 10^-3) I found a feasible option at 8\\*10^-5, using which need average score was achieved after 1000 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.00\tmax_step:14\n",
      "Episode 200\tAverage Score: 0.02\tmax_step:14\n",
      "Episode 300\tAverage Score: 0.05\tmax_step:17\n",
      "Episode 400\tAverage Score: 0.05\tmax_step:15\n",
      "Episode 500\tAverage Score: 0.06\tmax_step:30\n",
      "Episode 600\tAverage Score: 0.07\tmax_step:60\n",
      "Episode 700\tAverage Score: 0.11\tmax_step:14\n",
      "Episode 800\tAverage Score: 0.21\tmax_step:30\n",
      "Episode 900\tAverage Score: 0.32\tmax_step:71\n",
      "Episode 1000\tAverage Score: 0.76\tmax_step:29\n",
      "Score is higher than 0.5\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import torch\n",
    "from workspace_utils import active_session\n",
    "\n",
    "def ddpg(n_episodes=10000,print_every=100):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    for agent in agents: # do not forget to reset all agents\n",
    "        agent.reset()\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        for agent in agents:\n",
    "            agent.reset() # reset every agent for each episode\n",
    "        states = env_info.vector_observations\n",
    "        score = np.zeros(num_agents) # score should be represented as an array due to presence of multiple agents\n",
    "        num_step = 0\n",
    "        while True:\n",
    "            actions = np.stack(agent.act(state) for agent, state in zip(agents, states))\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            for agent, s, a, r, n, d in zip(agents, states, actions, rewards, next_states, dones):\n",
    "                agent.step(s, a, r, n, d) # act with every agent\n",
    "            states = next_states # move all agents to next states\n",
    "            score += np.array(rewards) # update scores\n",
    "            num_step += 1 # move to next iteration\n",
    "            if any(dones):\n",
    "                break # if episode was finished due to dropping the ball - break and record score\n",
    "        print('\\rEpisode {}\\tReward: {:.2f}'.format(i_episode, np.sum(rewards)), end=\"\")\n",
    "        scores_deque.append(np.max(score)) # get the maximum score of all agents\n",
    "        scores.append(np.max(score)) # record this score\n",
    "        for i, agent in enumerate(agents):\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor_{:02d}.pth'.format(i))\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic_{:02d}.pth'.format(i))\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}\\tmax_step:{}'.format(i_episode, np.mean(scores_deque), num_step))\n",
    "            if np.mean(scores_deque) >= 0.5:\n",
    "                print(\"Score is higher than 0.5\")\n",
    "                break\n",
    "    return scores\n",
    "\n",
    "with active_session(): # used to avoid workspace restart due to long-running learning process\n",
    "    scores = ddpg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize results of the agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea20620cf8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(scores, 'o-')\n",
    "plt.grid()\n",
    "plt.title('Reward Records')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main issue with this implementation of the agent is its stability. Various tricks can be deployed to improve that, such as clipping of the gradients, prioritized experience replay(so that agent learns more from useful interactions). Learning from the raw pixels would also a great challenge, given that even the original problem is hard enough with high chances of divergence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
